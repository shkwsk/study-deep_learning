# ゼロから作るDeep Learning
Pythonで学ぶディープラーニングの理論と実装

# 3. ニューラルネットワーク
* 分類問題: 入力データがどのクラスに属するか（例: 人が写った画像から性別を判定）（離散的）
* 回帰問題: 入力データから数値の予測を行う（例: 人が写った画像から体重を予測）（連続的）

## forward propagation
入力 -(重み)-> 隠れ層 -(重み)-> 出力層
隠れ層 & 出力層では活性化関数を適用する
重み付けと推論（活性化）を繰り返していくイメージ

## 活性化関数
* ステップ関数
* シグモイド関数
* ReLU（ランプ関数）

出力層によく用いられる
* ソフトマックス関数
* 恒等関数

## バッチ処理
入力データ(N次元)をM個まとめて処理する
出力データ(<分類クラス数>次元)はM個まとめて出力される
データの読み込み処理をM個まとめることができるので、リソースを演算に回すことができる


# 4. ニューラルネットワークの学習
## 損失関数
* 二乗和誤差
* 交差エントロピー誤差

## ミニバッチ学習
N個の訓練データの中からランダムにm個を選んで学習すること

## 勾配
重みパラメータの損失関数を減らす方向のこと
中心差分で数値偏微分を行い勾配を求める

## パラメータの更新
重みパラメータを学習率に合わせて更新する
勾配でパラメータを更新することを勾配降下法という

## 確率的勾配降下法（SGD）
無作為に選び出したデータに対して行う勾配降下法

